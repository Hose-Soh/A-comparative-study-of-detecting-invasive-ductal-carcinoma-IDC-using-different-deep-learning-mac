{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>mobilenetV2</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import imgaug as ia\n",
    "import numpy as np\n",
    "\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"><b>START: DATA</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2500\n",
       "1    2500\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(labels='Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Pathes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12906</td>\n",
       "      <td>0</td>\n",
       "      <td>archive/12906/0/12906_idx5_x1051_y1301_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16568</td>\n",
       "      <td>0</td>\n",
       "      <td>archive/16568/0/16568_idx5_x1151_y1201_class0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID  Diagnosis                                             Pathes\n",
       "0       12906          0  archive/12906/0/12906_idx5_x1051_y1301_class0.png\n",
       "1       16568          0  archive/16568/0/16568_idx5_x1151_y1201_class0.png"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>train test split</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df,test_size=0.3,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test , df_evaluate = train_test_split(df_test,test_size=0.3,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    539\n",
       "1    511\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    237\n",
       "0    213\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluate[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Pathes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>13617</td>\n",
       "      <td>0</td>\n",
       "      <td>archive/13617/0/13617_idx5_x1401_y151_class0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>9323</td>\n",
       "      <td>0</td>\n",
       "      <td>archive/9323/0/9323_idx5_x1801_y1251_class0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient ID  Diagnosis                                            Pathes\n",
       "4215       13617          0  archive/13617/0/13617_idx5_x1401_y151_class0.png\n",
       "3847        9323          0   archive/9323/0/9323_idx5_x1801_y1251_class0.png"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Pathes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15633</td>\n",
       "      <td>1</td>\n",
       "      <td>archive/15633/1/15633_idx5_x1551_y451_class1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>9123</td>\n",
       "      <td>0</td>\n",
       "      <td>archive/9123/0/9123_idx5_x951_y2301_class0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient ID  Diagnosis                                            Pathes\n",
       "22         15633          1  archive/15633/1/15633_idx5_x1551_y451_class1.png\n",
       "2735        9123          0    archive/9123/0/9123_idx5_x951_y2301_class0.png"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1752\n",
       "0    1748\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    539\n",
       "1    511\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>getting the training data from directory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# random_train['Pixels']=np.array(random_train['Pathes'].map(lambda x:np.asarray(open(x).resize((128,128)))))\n",
    "# X_train_mobilenet=df_train['Pathes'].map(lambda x:np.asarray(Image.open(x).resize((128,128))))\n",
    "X_train_mobilenet=df_train['Pathes'].map(lambda x:np.asarray(Image.open(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mobilenet = np.array(df_train['Diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"><b>FINISH: DATA</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>start: data generator</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224,224)\n",
    "train_batches = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=90,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   )\n",
    "test_batches = test_datagen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_batches = test_datagen.flow_from_dataframe(dataframe=df_evaluate,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " preds (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "num_classes = 1\n",
    "model = Sequential([\n",
    "     MobileNetV2(input_shape=(224,224,3),weights=\"imagenet\",include_top=False), \n",
    "     GlobalAveragePooling2D(),\n",
    "     Dense(num_classes, activation='sigmoid',name='preds'),\n",
    "])\n",
    "model.layers[0].trainable= False\n",
    "# show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fahim\\AppData\\Local\\Temp/ipykernel_13900/3573417681.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  trained_MobileNetV2 = model.fit_generator(train_batches,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 [==============================] - 62s 1s/step - loss: 0.5379 - accuracy: 0.7334 - val_loss: 0.4505 - val_accuracy: 0.8044\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - 60s 1s/step - loss: 0.4646 - accuracy: 0.7949 - val_loss: 0.4094 - val_accuracy: 0.8178\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - 59s 1s/step - loss: 0.4460 - accuracy: 0.7991 - val_loss: 0.4201 - val_accuracy: 0.8044\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - 60s 1s/step - loss: 0.4257 - accuracy: 0.8154 - val_loss: 0.4011 - val_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - 60s 1s/step - loss: 0.4244 - accuracy: 0.8143 - val_loss: 0.3976 - val_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - 59s 1s/step - loss: 0.4189 - accuracy: 0.8111 - val_loss: 0.3824 - val_accuracy: 0.8289\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.4129 - accuracy: 0.8220 - val_loss: 0.3840 - val_accuracy: 0.8400\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.4110 - accuracy: 0.8211 - val_loss: 0.4013 - val_accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.3955 - val_accuracy: 0.8311\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=keras.losses.binary_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "trained_MobileNetV2 = model.fit_generator(train_batches,\n",
    "#           validation_data=test_batches,\n",
    "          validation_data=valid_batches,\n",
    "          epochs=20,\n",
    "#           validation_split=0.2,\n",
    "          verbose=1,\n",
    "          callbacks=[callbacks]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 18s 1s/step - loss: 0.4378 - accuracy: 0.8124\n"
     ]
    }
   ],
   "source": [
    "model_mobilenet_score = model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "y_pred_mobilenet_aug=(model.predict(test_batches) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mobilenet_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       476\n",
      "           1       0.86      0.77      0.81       574\n",
      "\n",
      "    accuracy                           0.81      1050\n",
      "   macro avg       0.81      0.81      0.81      1050\n",
      "weighted avg       0.81      0.81      0.81      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_mobilenet_aug,np.array(df_test[\"Diagnosis\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(trained):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(trained.epoch, trained.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(trained.epoch, trained.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(trained.epoch, trained.history[\"accuracy\"], label=\"Train acc\")\n",
    "    ax[1].plot(trained.epoch, trained.history[\"val_accuracy\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss(trained_MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mobilenetV2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>feature map of mobilenetV2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# img = img_to_array(test)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# X_train_mobilenet[0].shape\n",
    "img = X_train_mobilenet[0]\n",
    "img = np.expand_dims(img, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 50, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_3:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 50, 50, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 50, 50, 3).\n"
     ]
    }
   ],
   "source": [
    "first_feature_map = tf.keras.models.Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "feature_map_1=first_feature_map.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1280)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_3:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 50, 50, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_4:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 50, 50, 3).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_feature_map = tf.keras.models.Model(inputs=model.inputs, outputs=model.layers[2].output)\n",
    "feature_map_2=second_feature_map.predict(img)\n",
    "feature_map_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>finish [datagen]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1752\n",
       "0    1748\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "img_list = []\n",
    "for i in range (0,len(X_train_mobilenet)):\n",
    "    brain_img =np.array(X_train_mobilenet)[i]\n",
    "    img_arr = img_to_array(brain_img).astype(np.float32)\n",
    "    img_list.append(preprocess_input(img_arr))\n",
    "X_train_mobilenet = np.array(img_list)\n",
    "\n",
    "print(X_train_mobilenet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , GlobalAveragePooling2D\n",
    "from keras.applications import MobileNetV2\n",
    "num_classes = 1\n",
    "model = Sequential([\n",
    "     MobileNetV2(input_shape=(224,224,3),weights=\"imagenet\",include_top=False), \n",
    "     GlobalAveragePooling2D(),\n",
    "     Dense(num_classes, activation='sigmoid',name='preds'),\n",
    "])\n",
    "model.layers[0].trainable= False\n",
    "# show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.6907WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "88/88 [==============================] - 38s 435ms/step - loss: 0.6040 - accuracy: 0.6907 - val_loss: 0.4574 - val_accuracy: 0.7886\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 37s 426ms/step - loss: 0.4549 - accuracy: 0.7993 - val_loss: 0.4311 - val_accuracy: 0.8129\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 38s 432ms/step - loss: 0.4159 - accuracy: 0.8246 - val_loss: 0.4281 - val_accuracy: 0.8071\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 38s 429ms/step - loss: 0.3947 - accuracy: 0.8343 - val_loss: 0.4141 - val_accuracy: 0.8157\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 37s 425ms/step - loss: 0.3818 - accuracy: 0.8332 - val_loss: 0.4095 - val_accuracy: 0.8214\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 38s 433ms/step - loss: 0.3638 - accuracy: 0.8486 - val_loss: 0.4166 - val_accuracy: 0.8057\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 38s 429ms/step - loss: 0.3554 - accuracy: 0.8536 - val_loss: 0.4097 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 37s 425ms/step - loss: 0.3436 - accuracy: 0.8529 - val_loss: 0.4122 - val_accuracy: 0.8257\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 37s 426ms/step - loss: 0.3359 - accuracy: 0.8596 - val_loss: 0.4152 - val_accuracy: 0.8271\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 38s 427ms/step - loss: 0.3304 - accuracy: 0.8611 - val_loss: 0.4140 - val_accuracy: 0.8114\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 38s 427ms/step - loss: 0.3244 - accuracy: 0.8657 - val_loss: 0.4172 - val_accuracy: 0.8086\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 38s 426ms/step - loss: 0.3189 - accuracy: 0.8671 - val_loss: 0.4179 - val_accuracy: 0.8114\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 37s 426ms/step - loss: 0.3109 - accuracy: 0.8714 - val_loss: 0.4230 - val_accuracy: 0.8114\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 37s 425ms/step - loss: 0.3069 - accuracy: 0.8771 - val_loss: 0.4245 - val_accuracy: 0.8200\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 38s 427ms/step - loss: 0.3010 - accuracy: 0.8754 - val_loss: 0.4357 - val_accuracy: 0.8200\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 37s 426ms/step - loss: 0.2979 - accuracy: 0.8807 - val_loss: 0.4291 - val_accuracy: 0.8114\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 38s 427ms/step - loss: 0.2915 - accuracy: 0.8850 - val_loss: 0.4296 - val_accuracy: 0.8171\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 37s 425ms/step - loss: 0.2900 - accuracy: 0.8854 - val_loss: 0.4350 - val_accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 38s 433ms/step - loss: 0.2854 - accuracy: 0.8850 - val_loss: 0.4349 - val_accuracy: 0.8143\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 37s 426ms/step - loss: 0.2791 - accuracy: 0.8925 - val_loss: 0.4383 - val_accuracy: 0.8171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6488bf2280>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=keras.losses.binary_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train_mobilenet,\n",
    "          y_train_mobilenet,\n",
    "          epochs=20,\n",
    "          validation_split=0.2,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_test_mobilenet=df_test['Pathes'].map(lambda x:np.asarray(open(x).resize((128,128))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_test_mobilenet=np.array(df_test['Diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "for i in range (0,len(X_test_mobilenet)):\n",
    "    brain_img =np.array(X_test_mobilenet)[i]\n",
    "    img_arr = img_to_array(brain_img).astype(np.float32)\n",
    "    img_list.append(preprocess_input(img_arr))\n",
    "X_test_mobilenet = np.array(img_list)\n",
    "print(X_test_mobilenet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 16s 338ms/step - loss: 0.4494 - accuracy: 0.8067\n",
      "The loss of the evaluation : 44.93723809719086\n",
      "The accuracy of the evaluation : 80.66666722297668\n"
     ]
    }
   ],
   "source": [
    "eval_score = model.evaluate(X_test_mobilenet,y_test_mobilenet)\n",
    "print('The loss of the evaluation :'+' '+str(eval_score[0]*100))\n",
    "print('The accuracy of the evaluation :'+' '+str(eval_score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"mobilenetv2_1.00_224_input_5:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_6:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "y_pred = model.predict_classes(X_test_mobilenet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "accuracy_score(y_test_mobilenet,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       752\n",
      "           1       0.82      0.79      0.80       748\n",
      "\n",
      "    accuracy                           0.81      1500\n",
      "   macro avg       0.81      0.81      0.81      1500\n",
      "weighted avg       0.81      0.81      0.81      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_mobilenet,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving weights and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad mode 'w'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-ca87fef236c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mobilenetV2_model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# serialize weights to HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mobilenetv2_weight.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"bad mode {repr(mode)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m         raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: bad mode 'w'"
     ]
    }
   ],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(\"mobilenetV2_model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"mobilenetv2_weight.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"mobilenetV2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inception Resnet V2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import imgaug as ia\n",
    "import numpy as np\n",
    "\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "\n",
    "%config InlineBackend.figure_format=\"svg\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop(labels='Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_train,df_validate=train_test_split(df_train, test_size=0.15,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE    = (299, 299)\n",
    "NUM_CLASSES   = 2\n",
    "BATCH_SIZE    = 8  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
    "NUM_EPOCHS    = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=90,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate,multiply, LocallyConnected2D, Lambda)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import imgaug as ia\n",
    "import numpy as np\n",
    "\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=90,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "valid_batches = valid_datagen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "net = InceptionResNetV2(include_top=False,\n",
    "                        weights='imagenet',\n",
    "                        input_tensor=None,\n",
    "                        input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0542aba9ea3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m net_final.compile(\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_final' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "net_final.compile(\n",
    "                  optimizer=Adam(lr=1e-2),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "437/437 [==============================] - 4276s 10s/step - loss: 7.6529 - accuracy: 0.4991 - val_loss: 7.6686 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "420/437 [===========================>..] - ETA: 2:28 - loss: 7.6686 - accuracy: 0.4994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-2d8afc59599c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m net_final.fit_generator(train_batches,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         epochs = NUM_EPOCHS)\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \"\"\"\n\u001b[1;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/computer-vision/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net_final.fit_generator(train_batches,\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = valid_batches,\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        epochs = NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_json = net_final.to_json()\n",
    "with open(\"inception_resnet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"inception_resnet_weight.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Inception Resnet V2 [Transfer Learning]</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import cv2 \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2,preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_INCEPTION = (75,75)\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_inception = InceptionResNetV2(\n",
    "#         input_shape = (IMAGE_SIZE_INCEPTION[0],IMAGE_SIZE_INCEPTION[1],3) ,\n",
    "#         weights = 'imagenet',\n",
    "#         include_top = False,\n",
    "#         pooling='max'\n",
    "\n",
    "# )\n",
    "# model_inception.trainable = False\n",
    "\n",
    "# x = Flatten()(model_inception.output)\n",
    "# x = Dense(NUM_CLASSES, activation = 'softmax')(x)\n",
    "\n",
    "# model1 = Model(inputs = model_inception.input , outputs = x)\n",
    "\n",
    "\n",
    "# # # #\n",
    "from tensorflow.keras import regularizers\n",
    "model_inception = InceptionResNetV2(\n",
    "        input_shape = (IMAGE_SIZE_INCEPTION[0],IMAGE_SIZE_INCEPTION[1],3) ,\n",
    "        weights = 'imagenet',\n",
    "        include_top = False,\n",
    "        pooling='max'\n",
    ")\n",
    "x=model_inception.output\n",
    "x=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.45, seed=123)(x)\n",
    "output=Dense(NUM_CLASSES-1, activation='sigmoid')(x)\n",
    "model=Model(inputs=model_inception.input, outputs=output)\n",
    "model.compile(Adamax(learning_rate=.01), loss='binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar(img):\n",
    "    return img/127.5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    \n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "#         shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "#         channel_shift_range=10,\n",
    "    \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "#         fill_mode='nearest',\n",
    "        preprocessing_function = scalar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = train_datagen.flow_from_dataframe(dataframe=df_train,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE_INCEPTION,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(preprocessing_function=scalar,\n",
    "                                   \n",
    "                                   rotation_range=90,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "#                                    shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "#                                    channel_shift_range=10,\n",
    "                                   \n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True\n",
    "#                                    fill_mode='nearest'\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches = valid_datagen.flow_from_dataframe(dataframe=df_evaluate,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE_INCEPTION,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = valid_datagen.flow_from_dataframe(dataframe=df_test,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"Pathes\",\n",
    "                                                  y_col=\"Diagnosis\",\n",
    "                                                  target_size=IMAGE_SIZE_INCEPTION,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='raw',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.compile(\n",
    "#     Adamax(lr=.001),\n",
    "#     loss = 'binary_crossentropy' , \n",
    "# #     optimizer = 'adam' , \n",
    "#     metrics = ['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         # Stop training when `val_loss` is no longer improving\n",
    "# #         monitor=\"val_loss\",\n",
    "#         monitor=\"val_loss\",\n",
    "#         # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "#         min_delta=1e-3,\n",
    "#         # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "#         patience=5,\n",
    "#         verbose=1,\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRA(tf.keras.callbacks.Callback):\n",
    "    reset=False\n",
    "    count=0\n",
    "    stop_count=0\n",
    "    tepochs=0\n",
    "    def __init__(self,model, patience,stop_patience, threshold, factor, dwell, model_name, freeze,batches, initial_epoch):\n",
    "        super(LRA, self).__init__()\n",
    "        self.model=model\n",
    "        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n",
    "        self.stop_patience=stop_patience\n",
    "        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
    "        self.factor=factor # factor by which to reduce the learning rate\n",
    "        self.dwell=dwell\n",
    "        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n",
    "        self.highest_tracc=0.0 # set highest training accuracy to 0\n",
    "        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n",
    "        #self.count=0 # initialize counter that counts epochs with no improvement\n",
    "        #self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement  \n",
    "        self.initial_epoch=initial_epoch \n",
    "        self.batches=batches\n",
    "        #self.epochs=epochs\n",
    "        best_weights=self.model.get_weights() # set a class vaiable so weights can be loaded after training is completed        \n",
    "        msg=' '\n",
    "        if freeze==True:\n",
    "            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n",
    "        else:\n",
    "            msgs=f' Starting training using base model { model_name} training all layers '            \n",
    "#         print_in_color (msgs, (244, 252, 3), (55,65,80)) \n",
    "    def on_train_begin(self, logs=None):\n",
    "        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n",
    "                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration', 'Batch')\n",
    "#         print_in_color(msg, (244,252,3), (55,65,80)) \n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        acc=logs.get('accuracy')* 100  # get training accuracy \n",
    "        loss=logs.get('loss')\n",
    "        msg='{0:60s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n",
    "        print(msg, '\\r', end='') # prints over on the same line to show running batch count\n",
    "        \n",
    "        \n",
    "    def on_epoch_begin(self,epoch, logs=None):\n",
    "        self.now= time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        later=time.time()\n",
    "        duration=later-self.now \n",
    "        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "        current_lr=lr\n",
    "        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        acc=logs.get('accuracy')  # get training accuracy \n",
    "        v_acc=logs.get('val_accuracy')\n",
    "        loss=logs.get('loss')\n",
    "        #print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n",
    "        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n",
    "            monitor='accuracy'\n",
    "            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n",
    "                self.highest_tracc=acc # set new highest training accuracy\n",
    "                LRA.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n",
    "                self.count=0 # set count to 0 since training accuracy improved\n",
    "                self.stop_count=0 # set stop counter to 0\n",
    "                if v_loss<self.lowest_vloss:\n",
    "                    self.lowest_vloss=v_loss\n",
    "                color= (0,255,0)\n",
    "                self.lr=lr\n",
    "            else: \n",
    "                # training accuracy did not improve check if this has happened for patience number of epochs\n",
    "                # if so adjust learning rate\n",
    "                if self.count>=self.patience -1:\n",
    "                    color=(245, 170, 66)\n",
    "                    self.lr= lr* self.factor # adjust the learning by factor\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                    self.count=0 # reset the count to 0\n",
    "                    self.stop_count=self.stop_count + 1\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(LRA.best_weights) # return to better point in N space                        \n",
    "                    else:\n",
    "                        if v_loss<self.lowest_vloss:\n",
    "                            self.lowest_vloss=v_loss                                    \n",
    "                else:\n",
    "                    self.count=self.count +1 # increment patience counter                    \n",
    "        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n",
    "            monitor='val_loss'\n",
    "            if v_loss< self.lowest_vloss: # check if the validation loss improved \n",
    "                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n",
    "                LRA.best_weights=self.model.get_weights() # validation loss improved so save the weights\n",
    "                self.count=0 # reset count since validation loss improved  \n",
    "                self.stop_count=0  \n",
    "                color=(0,255,0)\n",
    "                self.lr=lr\n",
    "            else: # validation loss did not improve\n",
    "                if self.count>=self.patience-1:\n",
    "                    color=(245, 170, 66)\n",
    "                    self.lr=self.lr * self.factor # adjust the learning rate                    \n",
    "                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted \n",
    "                    self.count=0 # reset counter\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n",
    "                else: \n",
    "                    self.count =self.count +1 # increment the patience counter                    \n",
    "                if acc>self.highest_tracc:\n",
    "                    self.highest_tracc= acc\n",
    "        msg=f'{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n",
    "#         print_in_color (msg,color, (55,65,80))\n",
    "        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n",
    "            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n",
    "#             print_in_color(msg, (0,255,0), (55,65,80))\n",
    "            self.model.stop_training = True # stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net1 = model1.fit(\n",
    "#         train_batch,\n",
    "#         validation_data = valid_batches,\n",
    "#         epochs = 100,\n",
    "#         callbacks = [callbacks]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"InceptionResnetV2\"\n",
    "batch_size=64\n",
    "train_steps = int(len(train_batch.labels)/batch_size)\n",
    "epochs =20\n",
    "patience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\n",
    "stop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\n",
    "threshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\n",
    "factor=.5 # factor to reduce lr by\n",
    "dwell=False # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\n",
    "freeze=False # if true free weights of  the base model\n",
    "\n",
    "callbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n",
    "                   factor=factor,dwell=dwell, model_name=model_name, freeze=freeze,batches=train_steps, initial_epoch=0 )]\n",
    "LRA.tepochs=epochs  # used to determine value of last epoch for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55/55 - 127s - loss: 4.6634 - accuracy: 0.7277 - val_loss: 14879178752.0000 - val_accuracy: 0.4733 - 127s/epoch - 2s/step6340 \n",
      "Epoch 2/20\n",
      "55/55 - 117s - loss: 0.9820 - accuracy: 0.7906 - val_loss: 3660.3323 - val_accuracy: 0.2467 - 117s/epoch - 2s/steps:  0.98203 \n",
      "Epoch 3/20\n",
      "55/55 - 117s - loss: 0.6102 - accuracy: 0.8094 - val_loss: 26.9830 - val_accuracy: 0.8200 - 117s/epoch - 2s/steposs:  0.61023 \n",
      "Epoch 4/20\n",
      "55/55 - 121s - loss: 0.5555 - accuracy: 0.8189 - val_loss: 0.9291 - val_accuracy: 0.7556 - 121s/epoch - 2s/steploss:  0.55547 \n",
      "Epoch 5/20\n",
      "55/55 - 117s - loss: 0.5310 - accuracy: 0.8140 - val_loss: 0.6694 - val_accuracy: 0.8378 - 117s/epoch - 2s/steploss:  0.53099 \n",
      "Epoch 6/20\n",
      "55/55 - 116s - loss: 0.5105 - accuracy: 0.8223 - val_loss: 0.6304 - val_accuracy: 0.8333 - 116s/epoch - 2s/steploss:  0.51051 \n",
      "Epoch 7/20\n",
      "55/55 - 118s - loss: 0.5061 - accuracy: 0.8257 - val_loss: 0.5940 - val_accuracy: 0.8467 - 118s/epoch - 2s/steploss:  0.50611 \n",
      "Epoch 8/20\n",
      "55/55 - 120s - loss: 0.5099 - accuracy: 0.8251 - val_loss: 0.6223 - val_accuracy: 0.8667 - 120s/epoch - 2s/steploss:  0.50993 \n",
      "Epoch 9/20\n",
      "55/55 - 119s - loss: 0.4939 - accuracy: 0.8243 - val_loss: 0.5295 - val_accuracy: 0.8556 - 119s/epoch - 2s/steploss:  0.49395 \n",
      "Epoch 10/20\n",
      "55/55 - 121s - loss: 0.4884 - accuracy: 0.8283 - val_loss: 0.5072 - val_accuracy: 0.8600 - 121s/epoch - 2s/steploss:  0.48839 \n",
      "Epoch 11/20\n",
      "55/55 - 119s - loss: 0.4819 - accuracy: 0.8271 - val_loss: 0.4862 - val_accuracy: 0.8667 - 119s/epoch - 2s/steploss:  0.48188 \n",
      "Epoch 12/20\n",
      "55/55 - 118s - loss: 0.4849 - accuracy: 0.8306 - val_loss: 0.4692 - val_accuracy: 0.8733 - 118s/epoch - 2s/steploss:  0.48491 \n",
      "Epoch 13/20\n",
      "55/55 - 117s - loss: 0.4831 - accuracy: 0.8297 - val_loss: 0.4555 - val_accuracy: 0.8622 - 117s/epoch - 2s/steploss:  0.48306 \n",
      "Epoch 14/20\n",
      "55/55 - 117s - loss: 0.4818 - accuracy: 0.8266 - val_loss: 0.4498 - val_accuracy: 0.8644 - 117s/epoch - 2s/steploss:  0.48178 \n",
      "Epoch 15/20\n",
      "55/55 - 116s - loss: 0.4752 - accuracy: 0.8326 - val_loss: 0.4574 - val_accuracy: 0.8600 - 116s/epoch - 2s/steploss:  0.47520 \n",
      "Epoch 16/20\n",
      "55/55 - 116s - loss: 0.4716 - accuracy: 0.8314 - val_loss: 0.4441 - val_accuracy: 0.8556 - 116s/epoch - 2s/steploss:  0.47155 \n",
      "Epoch 17/20\n",
      "55/55 - 117s - loss: 0.4757 - accuracy: 0.8269 - val_loss: 0.4504 - val_accuracy: 0.8622 - 117s/epoch - 2s/steploss:  0.47574 \n",
      "Epoch 18/20\n",
      "55/55 - 116s - loss: 0.4768 - accuracy: 0.8351 - val_loss: 0.4453 - val_accuracy: 0.8600 - 116s/epoch - 2s/steploss:  0.47683 \n",
      "Epoch 19/20\n",
      "55/55 - 119s - loss: 0.4723 - accuracy: 0.8314 - val_loss: 0.4398 - val_accuracy: 0.8689 - 119s/epoch - 2s/steploss:  0.47230 \n",
      "Epoch 20/20\n",
      "55/55 - 116s - loss: 0.4776 - accuracy: 0.8311 - val_loss: 0.4492 - val_accuracy: 0.8444 - 116s/epoch - 2s/steploss:  0.47760 \n"
     ]
    }
   ],
   "source": [
    "model1=model.fit(\n",
    "    x=train_batch,  \n",
    "    epochs=epochs, \n",
    "    verbose=2, \n",
    "    callbacks=callbacks,  \n",
    "    validation_data=valid_batches,\n",
    "#     validation_split=0.1,\n",
    "    validation_steps=None,  \n",
    "    shuffle=False,  \n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"InceptionResnetV2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"InceptionResnetV2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "y_pred_inception_resnet=model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inception_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inception_resnet = model.predict(test_batches)\n",
    "predicted_categories_inception_resnet = np.argmax(y_pred_inception_resnet, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories_inception_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories = tf.concat([y for x, y in test_batches], axis = 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories_argmax = np.argmax(true_categories, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_categories_argmax, predicted_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argmax(y_pred_inception_resnet,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_pred_inception_resnet,np.array(df_test[\"Diagnosis\"])))\n",
    "\n",
    "print(classification_report(np.argmax(y_pred_inception_resnet,axis=1),np.array(df_test[\"Diagnosis\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
    "    class_dict=test_gen.class_indices\n",
    "    labels= test_gen.labels\n",
    "    file_names= test_gen.filenames \n",
    "    error_list=[]\n",
    "    true_class=[]\n",
    "    pred_class=[]\n",
    "    prob_list=[]\n",
    "    new_dict={}\n",
    "    error_indices=[]\n",
    "    y_pred=[]\n",
    "    for key,value in class_dict.items():\n",
    "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
    "    # store new_dict as a text fine in the save_dir\n",
    "    classes=list(new_dict.values())     # list of string of class names\n",
    "    dict_as_text=str(new_dict)\n",
    "    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n",
    "    dict_path=os.path.join(save_dir,dict_name)    \n",
    "    with open(dict_path, 'w') as x_file:\n",
    "        x_file.write(dict_as_text)    \n",
    "    errors=0      \n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index=np.argmax(p)        \n",
    "        true_index=labels[i]  # labels are integer values\n",
    "        if pred_index != true_index: # a misclassification has occurred\n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)            \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)    \n",
    "    if print_code !=0:\n",
    "        if errors>0:\n",
    "            if print_code>errors:\n",
    "                r=errors\n",
    "            else:\n",
    "                r=print_code           \n",
    "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "            for i in range(r):\n",
    "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(error_list[i], pred_class[i],true_class[i], ' ', prob_list[i])\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
    "        else:\n",
    "            msg='With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "    if errors>0:\n",
    "        plot_bar=[]\n",
    "        plot_class=[]\n",
    "        for  key, value in new_dict.items():        \n",
    "            count=error_indices.count(key) \n",
    "            if count!=0:\n",
    "                plot_bar.append(count) # list containg how many times a class c had an error\n",
    "                plot_class.append(value)   # stores the class \n",
    "        fig=plt.figure()\n",
    "        fig.set_figheight(len(plot_class)/3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(0, len(plot_class)):\n",
    "            c=plot_class[i]\n",
    "            x=plot_bar[i]\n",
    "            plt.barh(c, x, )\n",
    "            plt.title( ' Errors by Class on Test Set')\n",
    "    \n",
    "    if len(classes)<= 30:\n",
    "        # create a confusion matrix and a test report        \n",
    "        y_true= np.array(labels)        \n",
    "        y_pred=np.array(y_pred)        \n",
    "        cm = confusion_matrix(y_true, y_pred )\n",
    "        clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "        length=len(classes)\n",
    "        if length<8:\n",
    "            fig_width=8\n",
    "            fig_height=8\n",
    "        else:\n",
    "            fig_width= int(length * .5)\n",
    "            fig_height= int(length * .5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
    "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()    \n",
    "        print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info( train_batch, y_pred_inception_resnet, print_code, save_dir, subject )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLPClassifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# random_train['Pixels']=np.array(random_train['Pathes'].map(lambda x:np.asarray(open(x).resize((128,128)))))\n",
    "# random_train['Pixels']=random_train.loc[:,['Pathes']].map(lambda x:np.asarray(open(x).resize((128,128))))\n",
    "X_train_MLP=df_train['Pathes'].map(lambda x:np.asarray(Image.open(x).resize((50,50))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_MLP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "img_list = []\n",
    "for i in range (0,len(X_train_MLP)):\n",
    "    brain_img =np.array(X_train_MLP)[i]\n",
    "    img_arr = img_to_array(brain_img).astype(np.float32)\n",
    "    img_list.append(preprocess_input(img_arr))\n",
    "X_scaled = np.array(img_list)\n",
    "\n",
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shape = X_scaled.shape[1]*X_scaled.shape[2]*X_scaled.shape[3]\n",
    "X_Flatten = X_scaled.reshape(X_scaled.shape[0],X_train_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 7500)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_MLP=df_test[\"Pathes\"].map(lambda x:np.asarray(Image.open(x).resize((50,50))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "for i in range (0,len(X_test_MLP)):\n",
    "    brain_img =np.array(X_test_MLP)[i]\n",
    "    img_arr = img_to_array(brain_img).astype(np.float32)\n",
    "    image_list.append(preprocess_input(img_arr))\n",
    "X_scaled_test = np.array(image_list)\n",
    "\n",
    "print(X_scaled_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shape = X_scaled_test.shape[1]*X_scaled.shape[2]*X_scaled.shape[3]\n",
    "X_Flatten_test = X_scaled_test.reshape(X_scaled_test.shape[0],X_test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 7500)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Flatten_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71264637\n",
      "Validation score: 0.734286\n",
      "Iteration 2, loss = 0.54652444\n",
      "Validation score: 0.760000\n",
      "Iteration 3, loss = 0.50039471\n",
      "Validation score: 0.757143\n",
      "Iteration 4, loss = 0.45570056\n",
      "Validation score: 0.754286\n",
      "Iteration 5, loss = 0.42893629\n",
      "Validation score: 0.760000\n",
      "Iteration 6, loss = 0.44505738\n",
      "Validation score: 0.760000\n",
      "Iteration 7, loss = 0.40552424\n",
      "Validation score: 0.742857\n",
      "Iteration 8, loss = 0.39374725\n",
      "Validation score: 0.760000\n",
      "Iteration 9, loss = 0.38562157\n",
      "Validation score: 0.768571\n",
      "Iteration 10, loss = 0.35289749\n",
      "Validation score: 0.760000\n",
      "Iteration 11, loss = 0.33776067\n",
      "Validation score: 0.757143\n",
      "Iteration 12, loss = 0.31969076\n",
      "Validation score: 0.754286\n",
      "Iteration 13, loss = 0.33622847\n",
      "Validation score: 0.720000\n",
      "Iteration 14, loss = 0.31530564\n",
      "Validation score: 0.725714\n",
      "Iteration 15, loss = 0.28712972\n",
      "Validation score: 0.745714\n",
      "Iteration 16, loss = 0.25132564\n",
      "Validation score: 0.745714\n",
      "Iteration 17, loss = 0.23474540\n",
      "Validation score: 0.754286\n",
      "Iteration 18, loss = 0.22599922\n",
      "Validation score: 0.757143\n",
      "Iteration 19, loss = 0.24989091\n",
      "Validation score: 0.728571\n",
      "Iteration 20, loss = 0.20242783\n",
      "Validation score: 0.714286\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100), max_iter=400,\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=MLPClassifier(hidden_layer_sizes=(100,100),max_iter=400,verbose=2,early_stopping=True)\n",
    "clf.fit(X_Flatten,np.array(df_train[\"Diagnosis\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MLP=clf.predict(X_Flatten_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred_MLP, np.array(df_test[\"Diagnosis\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79       745\n",
      "           1       0.79      0.78      0.79       755\n",
      "\n",
      "    accuracy                           0.79      1500\n",
      "   macro avg       0.79      0.79      0.79      1500\n",
      "weighted avg       0.79      0.79      0.79      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_MLP, np.array(df_test[\"Diagnosis\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f941ffa95e0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.loss_curve_)\n",
    "plt.plot(clf.validation_scores_)\n",
    "plt.legend([\"Loss\", \"Validation Score\"], loc =\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
